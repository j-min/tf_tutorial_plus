{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot learning curve graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for pretty print\n",
    "from pprint import pprint\n",
    "\n",
    "# for tokenizer\n",
    "import re\n",
    "\n",
    "# for word counter in vocabulary dictionary\n",
    "from collections import Counter\n",
    "\n",
    "# for checkpoint paths\n",
    "import os\n",
    "\n",
    "# for fancy progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# for output_projection\n",
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "# for initial attention (not required ver1.2+)\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maximum length of input and target sentences including paddings\n",
    "enc_sentence_length = 10\n",
    "dec_sentence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch_size: 2\n",
    "input_batches = [\n",
    "    ['Hi What is your name?', 'Nice to meet you!'],\n",
    "    ['Which programming language do you use?', 'See you later.'],\n",
    "    ['Where do you live?', 'What is your major?'],\n",
    "    ['What do you want to drink?', 'What is your favorite beer?']]\n",
    "\n",
    "target_batches = [\n",
    "    ['Hi this is Jaemin.', 'Nice to meet you too!'],\n",
    "    ['I like Python.', 'Bye Bye.'],\n",
    "    ['I live in Seoul, South Korea.', 'I study industrial engineering.'],\n",
    "    ['Beer please!', 'Leffe brown!']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi What is your name?',\n",
       " 'Nice to meet you!',\n",
       " 'Which programming language do you use?',\n",
       " 'See you later.',\n",
       " 'Where do you live?',\n",
       " 'What is your major?',\n",
       " 'What do you want to drink?',\n",
       " 'What is your favorite beer?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_sentences = []\n",
    "for input_batch in input_batches:\n",
    "    all_input_sentences.extend(input_batch)\n",
    "    \n",
    "all_target_sentences = []\n",
    "for target_batch in target_batches:\n",
    "    all_target_sentences.extend(target_batch)\n",
    "\n",
    "# Example\n",
    "all_input_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '?', '?', '\"', 'sdfs', '%', '@', '#', '%']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(sentence):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", sentence)\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "tokenizer('Hello world?? \"sdfs%@#%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'!': 12,\n",
      "  '.': 19,\n",
      "  '?': 1,\n",
      "  'Hi': 8,\n",
      "  'Nice': 10,\n",
      "  'See': 17,\n",
      "  'What': 3,\n",
      "  'Where': 20,\n",
      "  'Which': 13,\n",
      "  '_PAD': 0,\n",
      "  'beer': 26,\n",
      "  'do': 6,\n",
      "  'drink': 24,\n",
      "  'favorite': 25,\n",
      "  'is': 4,\n",
      "  'language': 15,\n",
      "  'later': 18,\n",
      "  'live': 21,\n",
      "  'major': 22,\n",
      "  'meet': 11,\n",
      "  'name': 9,\n",
      "  'programming': 14,\n",
      "  'to': 7,\n",
      "  'use': 16,\n",
      "  'want': 23,\n",
      "  'you': 2,\n",
      "  'your': 5},\n",
      " {0: '_PAD',\n",
      "  1: '?',\n",
      "  2: 'you',\n",
      "  3: 'What',\n",
      "  4: 'is',\n",
      "  5: 'your',\n",
      "  6: 'do',\n",
      "  7: 'to',\n",
      "  8: 'Hi',\n",
      "  9: 'name',\n",
      "  10: 'Nice',\n",
      "  11: 'meet',\n",
      "  12: '!',\n",
      "  13: 'Which',\n",
      "  14: 'programming',\n",
      "  15: 'language',\n",
      "  16: 'use',\n",
      "  17: 'See',\n",
      "  18: 'later',\n",
      "  19: '.',\n",
      "  20: 'Where',\n",
      "  21: 'live',\n",
      "  22: 'major',\n",
      "  23: 'want',\n",
      "  24: 'drink',\n",
      "  25: 'favorite',\n",
      "  26: 'beer'},\n",
      " 26)\n",
      "\n",
      "\n",
      "({'!': 2,\n",
      "  ',': 19,\n",
      "  '.': 1,\n",
      "  'Beer': 25,\n",
      "  'Bye': 4,\n",
      "  'Hi': 5,\n",
      "  'I': 3,\n",
      "  'Jaemin': 8,\n",
      "  'Korea': 21,\n",
      "  'Leffe': 27,\n",
      "  'Nice': 9,\n",
      "  'Python': 15,\n",
      "  'Seoul': 18,\n",
      "  'South': 20,\n",
      "  '_PAD': 0,\n",
      "  'brown': 28,\n",
      "  'engineering': 24,\n",
      "  'in': 17,\n",
      "  'industrial': 23,\n",
      "  'is': 7,\n",
      "  'like': 14,\n",
      "  'live': 16,\n",
      "  'meet': 11,\n",
      "  'please': 26,\n",
      "  'study': 22,\n",
      "  'this': 6,\n",
      "  'to': 10,\n",
      "  'too': 13,\n",
      "  'you': 12},\n",
      " {0: '_PAD',\n",
      "  1: '.',\n",
      "  2: '!',\n",
      "  3: 'I',\n",
      "  4: 'Bye',\n",
      "  5: 'Hi',\n",
      "  6: 'this',\n",
      "  7: 'is',\n",
      "  8: 'Jaemin',\n",
      "  9: 'Nice',\n",
      "  10: 'to',\n",
      "  11: 'meet',\n",
      "  12: 'you',\n",
      "  13: 'too',\n",
      "  14: 'like',\n",
      "  15: 'Python',\n",
      "  16: 'live',\n",
      "  17: 'in',\n",
      "  18: 'Seoul',\n",
      "  19: ',',\n",
      "  20: 'South',\n",
      "  21: 'Korea',\n",
      "  22: 'study',\n",
      "  23: 'industrial',\n",
      "  24: 'engineering',\n",
      "  25: 'Beer',\n",
      "  26: 'please',\n",
      "  27: 'Leffe',\n",
      "  28: 'brown'},\n",
      " 28)\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(sentences, is_target=False, max_vocab_size=None):\n",
    "    word_counter = Counter()\n",
    "    vocab = dict()\n",
    "    reverse_vocab = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        word_counter.update(tokens)\n",
    "        \n",
    "    if max_vocab_size is None:\n",
    "        max_vocab_size = len(word_counter)\n",
    "    \n",
    "    if is_target:\n",
    "        vocab['_GO'] = 0\n",
    "        vocab['_PAD'] = 1\n",
    "        vocab_idx = 2\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    else:\n",
    "        vocab['_PAD'] = 0\n",
    "        vocab_idx = 1\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "            \n",
    "    for key, value in vocab.items():\n",
    "        reverse_vocab[value] = key\n",
    "            \n",
    "    return vocab, reverse_vocab, max_vocab_size\n",
    "\n",
    "# Example\n",
    "pprint(build_vocab(all_input_sentences))\n",
    "print('\\n')\n",
    "pprint(build_vocab(all_target_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocabulary size: 26\n",
      "target vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "enc_vocab, enc_reverse_vocab, enc_vocab_size = build_vocab(all_input_sentences)\n",
    "dec_vocab, dec_reverse_vocab, dec_vocab_size = build_vocab(all_target_sentences, is_target=True)\n",
    "\n",
    "print('input vocabulary size:', enc_vocab_size)\n",
    "print('target vocabulary size:', dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice 10\n",
      "to 7\n",
      "meet 11\n",
      "you 2\n",
      "! 12\n"
     ]
    }
   ],
   "source": [
    "def token2idx(word, vocab):\n",
    "    return vocab[word]\n",
    "\n",
    "for token in tokenizer('Nice to meet you!'):\n",
    "    print(token, token2idx(token, enc_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi What is your name?\n",
      "([8, 3, 4, 5, 9, 1, 0, 0, 0, 0], 6)\n",
      "Hi this is Jaemin.\n",
      "([0, 6, 7, 8, 9, 2, 1, 1, 1, 1, 1], 5)\n"
     ]
    }
   ],
   "source": [
    "def sent2idx(sent, vocab=enc_vocab, max_sentence_length=enc_sentence_length, is_target=False):\n",
    "    tokens = tokenizer(sent)\n",
    "    current_length = len(tokens)\n",
    "    pad_length = max_sentence_length - current_length\n",
    "    if is_target:\n",
    "        return [0] + [token2idx(token, vocab) for token in tokens] + [1] * pad_length, current_length\n",
    "    else:\n",
    "        return [token2idx(token, vocab) for token in tokens] + [0] * pad_length, current_length\n",
    "\n",
    "# Enc Example\n",
    "print('Hi What is your name?')\n",
    "print(sent2idx('Hi What is your name?'))\n",
    "\n",
    "# Dec Example\n",
    "print('Hi this is Jaemin.')\n",
    "print(sent2idx('Hi this is Jaemin.', vocab=dec_vocab, max_sentence_length=dec_sentence_length, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idx2token(idx, reverse_vocab):\n",
    "    return reverse_vocab[idx]\n",
    "\n",
    "def idx2sent(indices, reverse_vocab=dec_reverse_vocab):\n",
    "    return \" \".join([idx2token(idx, reverse_vocab) for idx in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters / Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DemoConfig:\n",
    "    \n",
    "    # Model\n",
    "    hidden_size = 30\n",
    "    enc_emb_size = 30\n",
    "    dec_emb_size = 30\n",
    "    attn_size = 30\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell\n",
    "    \n",
    "    # Training\n",
    "    optimizer = tf.train.RMSPropOptimizer\n",
    "    n_epoch = 801\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Tokens\n",
    "    start_token = 0 # GO\n",
    "    end_token = 1 # PAD\n",
    "\n",
    "    # Checkpoint Path\n",
    "    ckpt_dir = './ckpt_dir/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    def __init__(self, config, mode='training'):\n",
    "        assert mode in ['training', 'evaluation', 'inference']\n",
    "        self.mode = mode\n",
    "\n",
    "        # Model\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.enc_emb_size = config.enc_emb_size\n",
    "        self.dec_emb_size = config.dec_emb_size\n",
    "        self.attn_size = config.attn_size\n",
    "        self.cell = config.cell\n",
    "        \n",
    "        # Training\n",
    "        self.optimizer = config.optimizer\n",
    "        self.n_epoch = config.n_epoch\n",
    "        self.learning_rate = config.learning_rate\n",
    "        \n",
    "        # Tokens\n",
    "        self.start_token = config.start_token\n",
    "        self.end_token = config.end_token\n",
    "        \n",
    "        # Checkpoint Path\n",
    "        self.ckpt_dir = config.ckpt_dir\n",
    "        \n",
    "    def add_placeholders(self):\n",
    "        self.enc_inputs = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None, enc_sentence_length],\n",
    "            name='input_sentences')\n",
    "\n",
    "        self.enc_sequence_length = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None,],\n",
    "            name='input_sequence_length')\n",
    "        \n",
    "        if self.mode == 'training':\n",
    "            self.dec_inputs = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None, dec_sentence_length+1],\n",
    "                name='target_sentences')\n",
    "\n",
    "            self.dec_sequence_length = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None,],\n",
    "                name='target_sequence_length')\n",
    "            \n",
    "    def add_encoder(self):\n",
    "        with tf.variable_scope('Encoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.enc_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([enc_vocab_size+1, self.enc_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            # [Batch_size x enc_sent_len x embedding_size]\n",
    "            enc_emb_inputs = tf.nn.embedding_lookup(\n",
    "                self.enc_Wemb, self.enc_inputs, name='emb_inputs')\n",
    "            enc_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # enc_outputs: [batch_size x enc_sent_len x embedding_size]\n",
    "            # enc_last_state: [batch_size x embedding_size]\n",
    "            self.enc_outputs, self.enc_last_state = tf.nn.dynamic_rnn(\n",
    "                cell=enc_cell,\n",
    "                inputs=enc_emb_inputs,\n",
    "                sequence_length=self.enc_sequence_length,\n",
    "                time_major=False,\n",
    "                dtype=tf.float32)\n",
    "            \n",
    "    def add_decoder(self):\n",
    "        with tf.variable_scope('Decoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.dec_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([dec_vocab_size+2, self.dec_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "            \n",
    "            # get dynamic batch_size\n",
    "            batch_size = tf.shape(self.enc_inputs)[0]\n",
    "\n",
    "            dec_cell = self.cell(self.hidden_size)\n",
    "            \n",
    "            attn_mech = tf.contrib.seq2seq.LuongAttention(\n",
    "                num_units=self.attn_size,\n",
    "                memory=self.enc_outputs,\n",
    "                memory_sequence_length=self.enc_sequence_length,\n",
    "                normalize=False,\n",
    "                name='LuongAttention')\n",
    "\n",
    "            dec_cell = tf.contrib.seq2seq.DynamicAttentionWrapper(\n",
    "                cell=dec_cell,\n",
    "                attention_mechanism=attn_mech,\n",
    "                attention_size=self.attn_size,\n",
    "                # attention_history=False (in ver 1.2)\n",
    "                name='Attention_Wrapper')\n",
    "            \n",
    "            initial_state = tf.contrib.seq2seq.DynamicAttentionWrapperState(\n",
    "                cell_state=self.enc_last_state,\n",
    "                attention=_zero_state_tensors(self.attn_size, batch_size, tf.float32))\n",
    "\n",
    "            # output projection (replacing `OutputProjectionWrapper`)\n",
    "            output_layer = Dense(dec_vocab_size+2, name='output_projection')\n",
    "            \n",
    "            if self.mode == 'training':\n",
    "\n",
    "                # maxium unrollings in current batch = max(dec_sent_len) + 1(GO symbol)\n",
    "                max_dec_len = tf.reduce_max(self.dec_sequence_length+1, name='max_dec_len')\n",
    "\n",
    "                dec_emb_inputs = tf.nn.embedding_lookup(\n",
    "                    self.dec_Wemb, self.dec_inputs, name='emb_inputs')\n",
    "        \n",
    "                training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                    inputs=dec_emb_inputs,\n",
    "                    sequence_length=self.dec_sequence_length+1,\n",
    "                    time_major=False,\n",
    "                    name='training_helper')\n",
    "\n",
    "                training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=training_helper,\n",
    "                    initial_state=initial_state,\n",
    "                    output_layer=output_layer) \n",
    "\n",
    "                train_dec_outputs, train_dec_last_state = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    training_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=max_dec_len)\n",
    "                \n",
    "                # dec_outputs: collections.namedtuple(rnn_outputs, sample_id)\n",
    "                # dec_outputs.rnn_output: [batch_size x max(dec_sequence_len) x dec_vocab_size+2], tf.float32\n",
    "                # dec_outputs.sample_id [batch_size], tf.int32\n",
    "                \n",
    "                # logits: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                logits = tf.identity(train_dec_outputs.rnn_output, name='logits')\n",
    "                \n",
    "                # targets: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                targets = tf.slice(self.dec_inputs, [0, 0], [-1, max_dec_len], 'targets')\n",
    "                \n",
    "                # masks: [batch_size x max_dec_len]\n",
    "                # => ignore outputs after `dec_senquence_length+1` when calculating loss\n",
    "                masks = tf.sequence_mask(self.dec_sequence_length+1, max_dec_len, dtype=tf.float32, name='masks')\n",
    "                \n",
    "                # Control loss dimensions with `average_across_timesteps` and `average_across_batch`\n",
    "                # internal: `tf.nn.sparse_softmax_cross_entropy_with_logits`\n",
    "                self.batch_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                    logits=logits,\n",
    "                    targets=targets,\n",
    "                    weights=masks,\n",
    "                    name='batch_loss')\n",
    "                \n",
    "                # prediction sample for validation\n",
    "                self.valid_predictions = tf.identity(train_dec_outputs.sample_id, name='valid_preds')\n",
    "\n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "            \n",
    "            elif self.mode == 'inference':\n",
    "            \n",
    "                start_tokens = tf.tile(tf.constant([self.start_token], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "            \n",
    "                inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                    embedding=self.dec_Wemb,\n",
    "                    start_tokens=start_tokens,\n",
    "                    end_token=self.end_token)\n",
    "                \n",
    "                inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=inference_helper,\n",
    "                    initial_state=initial_state,\n",
    "                    output_layer=output_layer)\n",
    "                \n",
    "                infer_dec_outputs, infer_dec_last_state = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    inference_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=dec_sentence_length)\n",
    "                \n",
    "                # [batch_size x dec_sentence_length], tf.int32\n",
    "                self.predictions = tf.identity(infer_dec_outputs.sample_id, name='predictions')\n",
    "                # equivalent to tf.argmax(infer_dec_outputs.rnn_output, axis=2, name='predictions')\n",
    "                \n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        \n",
    "    def add_training_op(self):\n",
    "        self.training_op = self.optimizer(self.learning_rate, name='training_op').minimize(self.batch_loss)\n",
    "        \n",
    "    def save(self, sess, var_list=None, save_path=None):\n",
    "        print(f'Saving model at {save_path}')\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        saver.save(sess, save_path, write_meta_graph=False)\n",
    "        \n",
    "    def restore(self, sess, var_list=None, ckpt_path=None):\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        self.restorer = tf.train.Saver(var_list)\n",
    "        self.restorer.restore(sess, ckpt_path)\n",
    "        print('Restore Finished!')\n",
    "        \n",
    "    def summary(self):\n",
    "        summary_writer = tf.summary.FileWriter(\n",
    "            logdir=self.ckpt_dir,\n",
    "            graph=tf.get_default_graph())\n",
    "        \n",
    "    def build(self):\n",
    "        self.add_placeholders()\n",
    "        self.add_encoder()\n",
    "        self.add_decoder()\n",
    "\n",
    "    def train(self, sess, data, from_scratch=False,\n",
    "              load_ckpt=None, save_path=None):\n",
    "        \n",
    "        # Restore Checkpoint\n",
    "        if from_scratch is False and os.path.isfile(load_ckpt):\n",
    "            self.restore(sess, load_ckpt)\n",
    "    \n",
    "        # Add Optimizer to current graph\n",
    "        self.add_training_op()\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        input_batches, target_batches = data\n",
    "        loss_history = []\n",
    "        \n",
    "        for epoch in tqdm(range(self.n_epoch)):\n",
    "\n",
    "            all_preds = []\n",
    "            epoch_loss = 0\n",
    "            for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "                input_batch_tokens = []\n",
    "                target_batch_tokens = []\n",
    "                enc_sentence_lengths = []\n",
    "                dec_sentence_lengths = []\n",
    "\n",
    "                for input_sent in input_batch:\n",
    "                    tokens, sent_len = sent2idx(input_sent)\n",
    "                    input_batch_tokens.append(tokens)\n",
    "                    enc_sentence_lengths.append(sent_len)\n",
    "\n",
    "                for target_sent in target_batch:\n",
    "                    tokens, sent_len = sent2idx(target_sent,\n",
    "                                 vocab=dec_vocab,\n",
    "                                 max_sentence_length=dec_sentence_length,\n",
    "                                 is_target=True)\n",
    "                    target_batch_tokens.append(tokens)\n",
    "                    dec_sentence_lengths.append(sent_len)\n",
    "       \n",
    "                # Evaluate 3 ops in the graph\n",
    "                # => valid_predictions, loss, training_op(optimzier)\n",
    "                batch_preds, batch_loss, _ = sess.run(\n",
    "                    [self.valid_predictions, self.batch_loss, self.training_op],\n",
    "                    feed_dict={\n",
    "                        self.enc_inputs: input_batch_tokens,\n",
    "                        self.enc_sequence_length: enc_sentence_lengths,\n",
    "                        self.dec_inputs: target_batch_tokens,\n",
    "                        self.dec_sequence_length: dec_sentence_lengths,\n",
    "                    })\n",
    "                # loss_history.append(batch_loss)\n",
    "                epoch_loss += batch_loss\n",
    "                all_preds.append(batch_preds)\n",
    "                \n",
    "            loss_history.append(epoch_loss)\n",
    "\n",
    "            # Logging every 400 epochs\n",
    "            if epoch % 400 == 0:\n",
    "                print('Epoch', epoch)\n",
    "                for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                    for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                        print(f'\\tInput: {input_sent}')\n",
    "                        print(f'\\tPrediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "                        print(f'\\tTarget:, {target_sent}')\n",
    "                print(f'\\tepoch loss: {epoch_loss:.2f}\\n')\n",
    "                \n",
    "        if save_path:\n",
    "            self.save(sess, save_path=save_path)\n",
    "\n",
    "        return loss_history\n",
    "    \n",
    "    def inference(self, sess, data, load_ckpt):\n",
    "        \n",
    "        self.restore(sess, ckpt_path=load_ckpt)\n",
    "        \n",
    "        input_batch, target_batch = data\n",
    "\n",
    "        batch_preds = []\n",
    "        batch_tokens = []\n",
    "        batch_sent_lens = []\n",
    "        \n",
    "        for input_sent in input_batch:\n",
    "            tokens, sent_len = sent2idx(input_sent)\n",
    "            batch_tokens.append(tokens)\n",
    "            batch_sent_lens.append(sent_len)\n",
    "            \n",
    "        batch_preds = sess.run(\n",
    "            self.predictions,\n",
    "            feed_dict={\n",
    "                self.enc_inputs: batch_tokens,\n",
    "                self.enc_sequence_length: batch_sent_lens,\n",
    "            })\n",
    "\n",
    "        for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "            print('Input:', input_sent)\n",
    "            print('Prediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "            print('Target:', target_sent, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if models are correctly built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='training')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Training model built!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='inference')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Inference model built!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/801 [00:00<02:18,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: this this this this this Beer _GO\n",
      "\tTarget:, Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: this this this this Beer Beer Beer\n",
      "\tTarget:, Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: industrial industrial industrial industrial Beer\n",
      "\tTarget:, I like Python.\n",
      "\tInput: See you later.\n",
      "\tPrediction: this industrial industrial industrial _GO\n",
      "\tTarget:, Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: this industrial industrial industrial industrial Beer Beer Beer Beer\n",
      "\tTarget:, I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "\tPrediction: this industrial industrial Beer Beer Beer _GO _GO _GO\n",
      "\tTarget:, I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: industrial industrial industrial industrial\n",
      "\tTarget:, Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: this this industrial industrial\n",
      "\tTarget:, Leffe brown!\n",
      "\tepoch loss: 13.67\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 402/801 [00:41<00:42,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, I like Python.\n",
      "\tInput: See you later.\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, Leffe brown!\n",
      "\tepoch loss: 0.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [01:22<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, I like Python.\n",
      "\tInput: See you later.\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, Leffe brown!\n",
      "\tepoch loss: 0.00\n",
      "\n",
      "Saving model at ./ckpt_dir/epoch_801_attention\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()     \n",
    "with tf.Session() as sess:\n",
    "    config = DemoConfig()\n",
    "    model = Seq2SeqModel(config, mode='training')\n",
    "    model.build()\n",
    "    data = (input_batches, target_batches)\n",
    "    loss_history = model.train(sess, data, from_scratch=True, save_path=model.ckpt_dir+f'epoch_{model.n_epoch}_attention')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAJcCAYAAABwj4S5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1104fa550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(model.n_epoch), loss_history)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Global step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir/epoch_801_attention\n",
      "Restore Finished!\n",
      "Input: Hi What is your name?\n",
      "Prediction: _GO Hi this is Jaemin . . . . .\n",
      "Target: Hi this is Jaemin. \n",
      "\n",
      "Input: Nice to meet you!\n",
      "Prediction: _GO Nice to meet you too ! ! you too\n",
      "Target: Nice to meet you too! \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir/epoch_801_attention\n",
      "Restore Finished!\n",
      "Input: Which programming language do you use?\n",
      "Prediction: _GO I like Python . . . . . .\n",
      "Target: I like Python. \n",
      "\n",
      "Input: See you later.\n",
      "Prediction: _GO Bye Bye . . . . . . .\n",
      "Target: Bye Bye. \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir/epoch_801_attention\n",
      "Restore Finished!\n",
      "Input: Where do you live?\n",
      "Prediction: _GO I live in Seoul , South Korea . .\n",
      "Target: I live in Seoul, South Korea. \n",
      "\n",
      "Input: What is your major?\n",
      "Prediction: _GO I study industrial engineering . . . . .\n",
      "Target: I study industrial engineering. \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir/epoch_801_attention\n",
      "Restore Finished!\n",
      "Input: What do you want to drink?\n",
      "Prediction: _GO Beer please ! ! you , ! ! you\n",
      "Target: Beer please! \n",
      "\n",
      "Input: What is your favorite beer?\n",
      "Prediction: _GO Leffe brown ! you you too ! you too\n",
      "Target: Leffe brown! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    model = Seq2SeqModel(config, mode='inference')\n",
    "    model.build()\n",
    "    for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "        data = (input_batch, target_batch)\n",
    "        model.inference(sess, data, load_ckpt=model.ckpt_dir+f'epoch_{model.n_epoch}_attention')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better inference than without scheduled sampling!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mldemo]",
   "language": "python",
   "name": "conda-env-mldemo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
